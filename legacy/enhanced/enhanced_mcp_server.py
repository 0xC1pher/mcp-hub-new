#!/usr/bin/env python3
"""
Enhanced MCP Server con Context Feedback System
Integra el sistema de retroalimentaci√≥n para prevenir alucinaciones
y mantener coherencia del proyecto.
"""

import json
import sys
import logging
import re
import time
from pathlib import Path
from typing import Dict, Any, List, Optional

logger = logging.getLogger(__name__)

# Agregar rutas al path para imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent / "servers" / "context-query"))
sys.path.insert(0, str(Path(__file__).parent.parent / "optimized"))

# Importar el sistema de retroalimentaci√≥n
try:
    from context_feedback_system import ContextFeedbackSystem, TaskPriority
    FEEDBACK_AVAILABLE = True
    logger.info("Context Feedback System cargado correctamente")
except ImportError as e:
    logger.warning(f"Context Feedback System no disponible: {e}")
    FEEDBACK_AVAILABLE = False
    
    # Crear clases dummy para compatibilidad
    class TaskPriority:
        HIGH = "high"
        MEDIUM = "medium"
        LOW = "low"
        CRITICAL = "critical"
    
    class ContextFeedbackSystem:
        def __init__(self, *args, **kwargs):
            pass

try:
    from optimized_mcp_server import OptimizedMCPContextServer
    logger.info("OptimizedMCPContextServer cargado correctamente")
except ImportError as e:
    logger.warning(f"OptimizedMCPContextServer no disponible: {e}")
    # Crear clase base m√≠nima
    class OptimizedMCPContextServer:
        def __init__(self):
            self.base_path = Path(__file__).parent
        
        def handle_tools_call(self, params):
            return {"content": [{"type": "text", "text": "Servidor en modo b√°sico"}]}

CACHE_AVAILABLE = False


class HallucinationDetector:
    """Detector de alucinaciones para prevenir respuestas incorrectas"""
    
    def __init__(self):
        self.known_facts = {}  # Base de conocimiento verificada
        self.suspicious_patterns = [
            r'definitivamente',
            r'siempre es',
            r'nunca falla',
            r'garantizado que',
            r'imposible que'
        ]
        self.context_inconsistencies = []
    
    def detect_hallucination_risks(self, query: str, context: str, proposed_response: str = "") -> Dict:
        """Detecta riesgos de alucinaci√≥n en la respuesta"""
        risks = {
            'confidence_level': 'medium',
            'risk_factors': [],
            'recommendations': [],
            'context_gaps': []
        }
        
        # Detectar patrones sospechosos
        for pattern in self.suspicious_patterns:
            if re.search(pattern, proposed_response.lower()):
                risks['risk_factors'].append(f'absolute_statement: {pattern}')
        
        # Detectar falta de contexto
        if len(context.strip()) < 100:
            risks['context_gaps'].append('insufficient_context')
            risks['confidence_level'] = 'low'
        
        # Detectar query ambigua
        if len(query.split()) < 3:
            risks['risk_factors'].append('ambiguous_query')
        
        # Generar recomendaciones
        if risks['risk_factors'] or risks['context_gaps']:
            risks['recommendations'] = self._generate_safety_recommendations(risks)
        
        return risks
    
    def _generate_safety_recommendations(self, risks: Dict) -> List[str]:
        """Genera recomendaciones para reducir riesgos"""
        recommendations = []
        
        if 'insufficient_context' in risks['context_gaps']:
            recommendations.append('request_more_context')
            recommendations.append('acknowledge_limitations')
        
        if any('absolute_statement' in rf for rf in risks['risk_factors']):
            recommendations.append('use_qualified_language')
            recommendations.append('provide_alternatives')
        
        return recommendations


class ContextValidator:
    """Validador de contexto para asegurar coherencia"""
    
    def __init__(self):
        self.context_history = []
        self.validation_rules = {
            'min_context_length': 50,
            'max_context_age': 3600,  # 1 hora
            'required_sections': ['description', 'examples']
        }
    
    def validate_context_quality(self, context: str, metadata: Dict = None) -> Dict:
        """Valida la calidad del contexto proporcionado"""
        validation = {
            'is_valid': True,
            'quality_score': 0.0,
            'issues': [],
            'improvements': []
        }
        
        # Validar longitud m√≠nima
        if len(context.strip()) < self.validation_rules['min_context_length']:
            validation['issues'].append('context_too_short')
            validation['is_valid'] = False
        
        # Validar estructura del contexto
        structure_score = self._assess_context_structure(context)
        validation['quality_score'] += structure_score * 0.4
        
        # Validar relevancia del contexto
        relevance_score = self._assess_context_relevance(context, metadata)
        validation['quality_score'] += relevance_score * 0.6
        
        # Generar mejoras sugeridas
        if validation['quality_score'] < 0.7:
            validation['improvements'] = self._suggest_context_improvements(context)
        
        return validation
    
    def _assess_context_structure(self, context: str) -> float:
        """Eval√∫a la estructura del contexto"""
        score = 0.0
        
        # Puntos por tener c√≥digo estructurado
        if re.search(r'(class|def|function)', context):
            score += 0.3
        
        # Puntos por tener documentaci√≥n
        if re.search(r'(""".*?"""|#.*)', context, re.DOTALL):
            score += 0.2
        
        # Puntos por tener ejemplos
        if 'example' in context.lower() or '```' in context:
            score += 0.3
        
        # Puntos por organizaci√≥n clara
        if re.search(r'(#{1,3}\s+|^\s*\d+\.)', context, re.MULTILINE):
            score += 0.2
        
        return min(1.0, score)
    
    def _assess_context_relevance(self, context: str, metadata: Dict = None) -> float:
        """Eval√∫a la relevancia del contexto"""
        if not metadata:
            return 0.5
        
        query = metadata.get('query', '')
        if not query:
            return 0.5
        
        # Calcular overlapping de keywords
        context_words = set(re.findall(r'\w+', context.lower()))
        query_words = set(re.findall(r'\w+', query.lower()))
        
        if not query_words:
            return 0.5
        
        overlap = len(context_words & query_words) / len(query_words)
        return min(1.0, overlap * 2)  # Multiplicar por 2 para dar m√°s peso
    
    def _suggest_context_improvements(self, context: str) -> List[str]:
        """Sugiere mejoras para el contexto"""
        improvements = []
        
        if len(context) < 200:
            improvements.append('add_more_detail')
        
        if not re.search(r'(example|ejemplo)', context.lower()):
            improvements.append('add_examples')
        
        if not re.search(r'(""".*?"""|#.*)', context, re.DOTALL):
            improvements.append('add_documentation')
        
        return improvements


class ModelGuidanceEngine:
    """Motor de gu√≠a para el modelo para respuestas m√°s precisas"""
    
    def __init__(self):
        self.guidance_templates = {
            'code_generation': {
                'structure': ['analysis', 'implementation', 'testing', 'documentation'],
                'avoid': ['hardcoded_values', 'missing_error_handling'],
                'include': ['type_hints', 'docstrings', 'examples']
            },
            'explanation': {
                'structure': ['overview', 'details', 'examples', 'summary'],
                'avoid': ['technical_jargon_without_explanation'],
                'include': ['step_by_step', 'visual_aids', 'analogies']
            },
            'debugging': {
                'structure': ['problem_identification', 'root_cause', 'solution', 'prevention'],
                'avoid': ['assumptions_without_verification'],
                'include': ['debugging_steps', 'testing_approach']
            }
        }
    
    def generate_guidance(self, query: str, context: str, intent: str = 'general') -> Dict:
        """Genera gu√≠as espec√≠ficas para el modelo"""
        guidance = {
            'response_structure': [],
            'focus_areas': [],
            'avoid_patterns': [],
            'quality_checks': [],
            'context_preservation': {}
        }
        
        # Obtener template basado en intenci√≥n
        template = self.guidance_templates.get(intent, {})
        
        if template:
            guidance['response_structure'] = template.get('structure', [])
            guidance['avoid_patterns'] = template.get('avoid', [])
            guidance['quality_checks'] = template.get('include', [])
        
        # Analizar √°reas de enfoque espec√≠ficas
        guidance['focus_areas'] = self._identify_focus_areas(query, context)
        
        # Reglas de preservaci√≥n de contexto
        guidance['context_preservation'] = self._get_preservation_rules(context)
        
        return guidance
    
    def _identify_focus_areas(self, query: str, context: str) -> List[str]:
        """Identifica √°reas espec√≠ficas de enfoque"""
        focus_areas = []
        
        # Extraer conceptos clave del query
        query_concepts = re.findall(r'\b[A-Z][a-zA-Z]+\b|\b[a-z_]+[a-z]\b', query)
        
        # Extraer conceptos del contexto
        context_concepts = re.findall(r'class\s+(\w+)|def\s+(\w+)|(\w+)\s*=', context)
        context_concepts = [c for group in context_concepts for c in group if c]
        
        # Intersecci√≥n de conceptos
        common_concepts = set(query_concepts) & set(context_concepts)
        focus_areas.extend(list(common_concepts)[:5])
        
        return focus_areas
    
    def _get_preservation_rules(self, context: str) -> Dict:
        """Obtiene reglas para preservar el contexto existente"""
        rules = {
            'coding_style': 'maintain_existing',
            'naming_convention': 'follow_existing',
            'documentation_style': 'match_existing',
            'error_handling': 'preserve_patterns'
        }
        
        # Detectar estilo de c√≥digo existente
        if context.count("'") > context.count('"'):
            rules['quote_style'] = 'single_quotes'
        elif context.count('"') > context.count("'"):
            rules['quote_style'] = 'double_quotes'
        
        # Detectar patr√≥n de indentaci√≥n
        if '\t' in context:
            rules['indentation'] = 'tabs'
        elif '    ' in context:
            rules['indentation'] = 'spaces'
        
        return rules


class ResponseQualityMonitor:
    """Monitor de calidad de respuestas para mejora continua"""
    
    def __init__(self):
        self.quality_metrics = {
            'accuracy': 0.0,
            'completeness': 0.0,
            'clarity': 0.0,
            'relevance': 0.0
        }
        self.response_history = []
    
    def evaluate_response_quality(self, query: str, context: str, response: str) -> Dict:
        """Eval√∫a la calidad de una respuesta"""
        evaluation = {
            'overall_score': 0.0,
            'metrics': {},
            'strengths': [],
            'improvements': [],
            'confidence': 'medium'
        }
        
        # Evaluar m√©tricas individuales
        evaluation['metrics']['relevance'] = self._assess_relevance(query, response)
        evaluation['metrics']['completeness'] = self._assess_completeness(query, response)
        evaluation['metrics']['clarity'] = self._assess_clarity(response)
        evaluation['metrics']['accuracy'] = self._assess_accuracy(context, response)
        
        # Calcular score general
        weights = {'relevance': 0.3, 'completeness': 0.25, 'clarity': 0.2, 'accuracy': 0.25}
        evaluation['overall_score'] = sum(
            evaluation['metrics'][metric] * weight 
            for metric, weight in weights.items()
        )
        
        # Determinar confianza
        if evaluation['overall_score'] >= 0.8:
            evaluation['confidence'] = 'high'
        elif evaluation['overall_score'] <= 0.5:
            evaluation['confidence'] = 'low'
        
        # Identificar fortalezas y mejoras
        evaluation['strengths'] = self._identify_strengths(evaluation['metrics'])
        evaluation['improvements'] = self._identify_improvements(evaluation['metrics'])
        
        return evaluation
    
    def _assess_relevance(self, query: str, response: str) -> float:
        """Eval√∫a qu√© tan relevante es la respuesta al query"""
        query_words = set(re.findall(r'\w+', query.lower()))
        response_words = set(re.findall(r'\w+', response.lower()))
        
        if not query_words:
            return 0.5
        
        overlap = len(query_words & response_words) / len(query_words)
        return min(1.0, overlap * 1.5)
    
    def _assess_completeness(self, query: str, response: str) -> float:
        """Eval√∫a qu√© tan completa es la respuesta"""
        # Heur√≠stica basada en longitud y estructura
        base_score = min(1.0, len(response) / 500)  # Normalizar por longitud esperada
        
        # Bonus por estructura organizada
        if re.search(r'(#{1,3}|\d+\.|\*\s)', response):
            base_score += 0.2
        
        # Bonus por incluir ejemplos
        if '```' in response or 'example' in response.lower():
            base_score += 0.2
        
        return min(1.0, base_score)
    
    def _assess_clarity(self, response: str) -> float:
        """Eval√∫a la claridad de la respuesta"""
        # M√©tricas de legibilidad b√°sicas
        sentences = len(re.split(r'[.!?]+', response))
        words = len(response.split())
        
        if sentences == 0:
            return 0.0
        
        avg_sentence_length = words / sentences
        
        # Penalizar oraciones muy largas o muy cortas
        if 10 <= avg_sentence_length <= 25:
            clarity_score = 0.8
        else:
            clarity_score = 0.5
        
        # Bonus por uso de formateo
        if any(marker in response for marker in ['**', '*', '`', '```']):
            clarity_score += 0.2
        
        return min(1.0, clarity_score)
    
    def _assess_accuracy(self, context: str, response: str) -> float:
        """Eval√∫a la precisi√≥n basada en el contexto"""
        # Verificar que no se contradiga el contexto
        context_facts = self._extract_facts(context)
        response_facts = self._extract_facts(response)
        
        if not context_facts:
            return 0.7  # Score neutral si no hay contexto para verificar
        
        # Verificar consistencia
        contradictions = 0
        for fact in response_facts:
            if any(self._facts_contradict(fact, cf) for cf in context_facts):
                contradictions += 1
        
        if contradictions == 0:
            return 1.0
        else:
            return max(0.0, 1.0 - (contradictions / len(response_facts)))
    
    def _extract_facts(self, text: str) -> List[str]:
        """Extrae 'hechos' b√°sicos del texto"""
        # Simplificado: extraer declaraciones que parecen hechos
        facts = []
        
        # Buscar patrones como "X es Y", "X tiene Y", etc.
        fact_patterns = [
            r'(\w+)\s+(?:es|is)\s+(\w+)',
            r'(\w+)\s+(?:tiene|has)\s+(\w+)',
            r'(\w+)\s*=\s*(\w+)'
        ]
        
        for pattern in fact_patterns:
            matches = re.findall(pattern, text.lower())
            facts.extend([f"{m[0]} -> {m[1]}" for m in matches])
        
        return facts
    
    def _facts_contradict(self, fact1: str, fact2: str) -> bool:
        """Verifica si dos hechos se contradicen"""
        # Simplificado: verificar si hablan del mismo sujeto pero con predicados diferentes
        parts1 = fact1.split(' -> ')
        parts2 = fact2.split(' -> ')
        
        if len(parts1) == 2 and len(parts2) == 2:
            return parts1[0] == parts2[0] and parts1[1] != parts2[1]
        
        return False
    
    def _identify_strengths(self, metrics: Dict) -> List[str]:
        """Identifica fortalezas de la respuesta"""
        strengths = []
        
        for metric, score in metrics.items():
            if score >= 0.8:
                strengths.append(f"high_{metric}")
        
        return strengths
    
    def _identify_improvements(self, metrics: Dict) -> List[str]:
        """Identifica √°reas de mejora"""
        improvements = []
        
        for metric, score in metrics.items():
            if score < 0.6:
                improvements.append(f"improve_{metric}")
        
        return improvements


class EnhancedMCPServer(OptimizedMCPContextServer):
    """Servidor MCP mejorado con sistema de retroalimentaci√≥n de contexto"""
    
    def __init__(self):
        super().__init__()
        
        project_root = Path(__file__).parent
        
        # Inicializar sistema de retroalimentaci√≥n si est√° disponible
        if FEEDBACK_AVAILABLE:
            self.feedback_system = ContextFeedbackSystem(str(project_root))
            logger.info("‚úÖ Context Feedback System inicializado")
        else:
            self.feedback_system = None
            logger.info("‚ùå Context Feedback System no disponible")
        
        # Inicializar cache inteligente si est√° disponible
        if CACHE_AVAILABLE:
            # DIRECTORIOS PRIORITARIOS OBLIGATORIOS para contexto del proyecto
            project_context_dir = project_root.parent.parent  # mcp-hub/
            cache_dir = project_root / "intelligent_cache"
            
            # Definir archivos prioritarios obligatorios
            self.priority_context_files = {
                "changelog": project_context_dir / "changelog.md",
                "checklist": project_context_dir / "checklist.md"
            }
            
            # Crear archivos prioritarios si no existen
            self._ensure_priority_context_files()
            
            self.intelligent_cache = IntelligentCacheSystem(
                source_directory=str(project_context_dir),
                cache_directory=str(cache_dir),
                l1_size=100,    # Acceso instant√°neo
                l2_size=1000,   # Datos frecuentes  
                disk_size=10000, # Hist√≥rico persistente
                chunk_size=1000,
                chunk_overlap=200
            )
            
            # Forzar carga inmediata de archivos prioritarios
            self._load_priority_context_immediately()
            
            logger.info("‚úÖ Cache Inteligente inicializado")
            logger.info(f"   üìÅ Directorio fuente: {project_context_dir}")
            logger.info(f"   üî• ARCHIVOS PRIORITARIOS OBLIGATORIOS:")
            logger.info(f"      üìã changelog.md - Estatus del proyecto")
            logger.info(f"      üìã checklist.md - Modelo de negocio, reglas, flujos")
            logger.info(f"   üíæ Cache L1: 100 items (instant√°neo)")
            logger.info(f"   üíæ Cache L2: 1000 items (frecuente)")
            logger.info(f"   üíæ Cache Disk: 10000+ items (hist√≥rico)")
        else:
            self.intelligent_cache = None
            self.priority_context_files = {}
            logger.info("‚ùå Cache Inteligente no disponible")
        
        # Contador de consultas para gesti√≥n de tareas
        self.query_count = 0
        self.context_review_threshold = 2
        
        # Sistema de feedback mejorado para prevenci√≥n de alucinaciones
        self.hallucination_detector = HallucinationDetector()
        self.context_validator = ContextValidator()
        self.model_guidance_engine = ModelGuidanceEngine()
        self.response_quality_monitor = ResponseQualityMonitor()
    
    def handle_tools_call(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Maneja llamadas a herramientas con retroalimentaci√≥n de contexto"""
        
        tool_name = params.get("name")
        arguments = params.get("arguments", {})
        
        # El feedback system siempre debe estar activo cuando est√© disponible
        # Solo usar modo compatibilidad si realmente no est√° disponible
        if not FEEDBACK_AVAILABLE or self.feedback_system is None:
            logger.info(f"Procesando herramienta en modo compatibilidad: {tool_name}")
            # A√∫n as√≠, intentar usar cache si est√° disponible
            if tool_name == "context_query" and CACHE_AVAILABLE and self.intelligent_cache:
                return self._handle_context_query_cache_only(arguments)
            return super().handle_tools_call(params)
        
        # REGLA PRIORITARIA: Leer feature.md antes de procesar
        try:
            feature_requirements = self.feedback_system.read_feature_requirements()
        except Exception as e:
            logger.warning(f"Error leyendo feature.md: {e}")
            feature_requirements = {}
        
        logger.info(f"Procesando herramienta con feedback: {tool_name}")
        
        if tool_name == "context_query":
            return self._handle_context_query_enhanced(arguments, feature_requirements)
        elif tool_name == "cache_search":
            return self._handle_cache_search(arguments)
        elif tool_name == "cache_metrics":
            return self._handle_cache_metrics(arguments)
        elif tool_name == "cache_refresh":
            return self._handle_cache_refresh(arguments)
        elif tool_name == "analyze_code":
            return self._handle_code_analysis(arguments)
        elif tool_name == "create_task":
            return self._handle_task_creation(arguments)
        elif tool_name == "process_tasks":
            return self._handle_task_processing(arguments)
        else:
            # Fallback al servidor original
            return super().handle_tools_call(params)
    
    def _handle_context_query_enhanced(self, arguments: Dict, feature_requirements: Dict) -> Dict[str, Any]:
        """Maneja consultas de contexto con cache inteligente y verificaciones mejoradas"""
        
        query = arguments.get("query", "")
        
        # Incrementar contador y verificar si necesita revisi√≥n de contexto
        self.query_count += 1
        
        try:
            # PASO 1: Buscar en cache inteligente primero (LOCAL, R√ÅPIDO)
            cache_results = []
            cache_hit = False
            
            if CACHE_AVAILABLE and self.intelligent_cache:
                cache_results = self.intelligent_cache.search(query, max_results=5)
                logger.info(f"üîç Cache search: {len(cache_results)} resultados encontrados")
                
                # Si encontramos resultados con buena relevancia, es un HIT
                if cache_results and cache_results[0].get('relevance', 0) > 0.6:
                    cache_hit = True
                    logger.info("‚úÖ CACHE HIT - Usando resultados del cache inteligente")
                    return self._format_cache_response(cache_results, query)
            
            # PASO 2: Si NO hay match en cache ‚Üí preguntar al MODELO
            logger.info("‚ùå CACHE MISS - Consultando modelo optimizado")
            
            # REGLA: Analizar c√≥digo existente antes de responder
            if self.query_count % self.context_review_threshold == 0:
                if FEEDBACK_AVAILABLE and self.feedback_system:
                    code_analysis = self.feedback_system.analyze_existing_code()
                    logger.info(f"Revisi√≥n de contexto realizada: {len(code_analysis.get('files_analyzed', []))} archivos")
            
            # Procesar consulta con el servidor optimizado original
            original_response = super().handle_tools_call({
                "name": "context_query",
                "arguments": arguments
            })
            
            # PASO 3: FEEDBACK SYSTEM guarda la respuesta en chunks para futuras b√∫squedas
            self._save_response_to_cache_via_feedback(query, original_response)
            
            # PASO 4: Combinar resultados si hab√≠a algo en cache (relevancia baja)
            if cache_results:
                enhanced_response = self._combine_cache_and_original_response(
                    cache_results, original_response, query, feature_requirements
                )
            else:
                # Verificar que la respuesta cumple con feature requirements
                enhanced_response = self._enhance_response_with_context(
                    original_response, 
                    query, 
                    feature_requirements
                )
            
            return enhanced_response
            
        except Exception as e:
            logger.error(f"Error en consulta mejorada: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error procesando consulta con feedback: {str(e)}"
                }],
                "isError": True
            }
    
    def _handle_code_analysis(self, arguments: Dict) -> Dict[str, Any]:
        """Maneja an√°lisis de c√≥digo existente"""
        
        target_path = arguments.get("path")
        
        try:
            analysis = self.feedback_system.analyze_existing_code(target_path)
            
            # Formatear respuesta
            response_text = self._format_code_analysis(analysis)
            
            return {
                "content": [{
                    "type": "text",
                    "text": response_text
                }]
            }
            
        except Exception as e:
            logger.error(f"Error en an√°lisis de c√≥digo: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error analizando c√≥digo: {str(e)}"
                }],
                "isError": True
            }
    
    def _handle_task_creation(self, arguments: Dict) -> Dict[str, Any]:
        """Maneja creaci√≥n de tareas"""
        
        content = arguments.get("content", "")
        priority = arguments.get("priority", "medium")
        dependencies = arguments.get("dependencies", [])
        
        try:
            task_priority = TaskPriority(priority.lower())
            task = self.feedback_system.create_task(
                content=content,
                priority=task_priority,
                dependencies=dependencies
            )
            
            return {
                "content": [{
                    "type": "text",
                    "text": f"Tarea creada: {task.id}\nContenido: {task.content}\nPrioridad: {task.priority.value}"
                }]
            }
            
        except Exception as e:
            logger.error(f"Error creando tarea: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error creando tarea: {str(e)}"
                }],
                "isError": True
            }
    
    def _handle_task_processing(self, arguments: Dict) -> Dict[str, Any]:
        """Maneja procesamiento de tareas con retroalimentaci√≥n"""
        
        try:
            results = self.feedback_system.process_tasks_with_context_feedback()
            
            # Formatear respuesta
            response_text = self._format_task_results(results)
            
            return {
                "content": [{
                    "type": "text",
                    "text": response_text
                }]
            }
            
        except Exception as e:
            logger.error(f"Error procesando tareas: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error procesando tareas: {str(e)}"
                }],
                "isError": True
            }
    
    def _enhance_response_with_context(self, original_response: Dict, query: str, 
                                     feature_requirements: Dict) -> Dict[str, Any]:
        """Mejora la respuesta original con verificaciones de contexto"""
        
        # Extraer texto de la respuesta original
        original_text = ""
        if "content" in original_response:
            for content_item in original_response["content"]:
                if content_item.get("type") == "text":
                    original_text += content_item.get("text", "")
        
        # Verificar que la respuesta cumple con los requerimientos
        compliance_check = self._verify_response_compliance(original_text, feature_requirements)
        
        # Agregar informaci√≥n de contexto si es necesario
        enhanced_text = original_text
        
        if not compliance_check["compliant"]:
            enhanced_text += f"\n\n‚ö†Ô∏è **Advertencia de Contexto**: {compliance_check['warning']}"
        
        # Agregar informaci√≥n de fuentes si est√° disponible
        if compliance_check.get("sources"):
            enhanced_text += f"\n\nüìö **Fuentes consultadas**: {', '.join(compliance_check['sources'])}"
        
        return {
            "content": [{
                "type": "text",
                "text": enhanced_text
            }],
            "context_metadata": {
                "compliance_check": compliance_check,
                "query_count": self.query_count,
                "feature_requirements_checked": True
            }
        }
    
    def _verify_response_compliance(self, response_text: str, feature_requirements: Dict) -> Dict[str, Any]:
        """Verifica que la respuesta cumple con los requerimientos de feature.md"""
        
        compliance = {
            "compliant": True,
            "warning": "",
            "sources": [],
            "checks_performed": []
        }
        
        # Verificar que no sea una respuesta inventada
        if "no se encontr√≥ informaci√≥n" not in response_text.lower() and len(response_text) < 50:
            compliance["compliant"] = False
            compliance["warning"] = "Respuesta muy corta, posible alucinaci√≥n"
        
        # Verificar que mencione fuentes espec√≠ficas
        if "secci√≥n" not in response_text.lower() and "archivo" not in response_text.lower():
            compliance["warning"] = "Respuesta no cita fuentes espec√≠ficas"
        
        compliance["checks_performed"] = ["length_check", "source_check", "hallucination_check"]
        
        return compliance
    
    def _format_code_analysis(self, analysis: Dict) -> str:
        """Formatea el resultado del an√°lisis de c√≥digo"""
        
        text = "# üìä An√°lisis de C√≥digo Existente\n\n"
        
        files_count = len(analysis.get("files_analyzed", []))
        text += f"**Archivos analizados**: {files_count}\n"
        
        functions_count = len(analysis.get("functions_found", []))
        text += f"**Funciones encontradas**: {functions_count}\n"
        
        classes_count = len(analysis.get("classes_found", []))
        text += f"**Clases encontradas**: {classes_count}\n"
        
        duplicates = analysis.get("duplicates_detected", [])
        if duplicates:
            text += f"\n‚ö†Ô∏è **Duplicados detectados**: {len(duplicates)}\n"
            for dup in duplicates[:3]:  # Mostrar solo los primeros 3
                text += f"  - {dup['type']}: {dup['name']} ({dup['count']} ocurrencias)\n"
        
        missing = analysis.get("missing_components", [])
        if missing:
            text += f"\nüîç **Componentes faltantes**: {len(missing)}\n"
            for comp in missing[:3]:
                text += f"  - {comp['type']}: {comp['description']}\n"
        
        recommendations = analysis.get("recommendations", [])
        if recommendations:
            text += f"\nüí° **Recomendaciones**:\n"
            for rec in recommendations[:3]:
                text += f"  - {rec}\n"
        
        return text
    
    def _format_task_results(self, results: Dict) -> str:
        """Formatea los resultados del procesamiento de tareas"""
        
        text = "# üéØ Resultados del Procesamiento de Tareas\n\n"
        
        processed = results.get("processed_tasks", [])
        text += f"**Tareas procesadas**: {len(processed)}\n"
        
        completed = [t for t in processed if t.get("status") == "completed"]
        text += f"**Tareas completadas**: {len(completed)}\n"
        
        errors = [t for t in processed if t.get("status") == "error"]
        if errors:
            text += f"**Tareas con errores**: {len(errors)}\n"
        
        context_reviews = results.get("context_reviews", [])
        text += f"**Revisiones de contexto**: {len(context_reviews)}\n"
        
        if context_reviews:
            latest_review = context_reviews[-1]
            coherence = latest_review.get("coherence_score", 1.0)
            text += f"**Coherencia actual**: {coherence:.2%}\n"
        
        recommendations = results.get("recommendations", [])
        if recommendations:
            text += f"\nüí° **Recomendaciones**:\n"
            for rec in recommendations:
                text += f"  - {rec}\n"
        
        return text
    
    def _ensure_priority_context_files(self):
        """Crea archivos prioritarios de contexto si no existen"""
        
        try:
            # Crear changelog.md si no existe
            changelog_file = self.priority_context_files["changelog"]
            if not changelog_file.exists():
                changelog_content = """# üìã Changelog del Proyecto - MCP Hub Enhanced

## Estado Actual del Proyecto

### ‚úÖ Completado
- [x] Sistema MCP base optimizado con 7 t√©cnicas avanzadas
- [x] Context Feedback System para prevenci√≥n de alucinaciones
- [x] Cache Inteligente Multinivel (L1/L2/Disk)
- [x] An√°lisis de c√≥digo existente obligatorio
- [x] Gesti√≥n de tareas con retroalimentaci√≥n
- [x] Detecci√≥n de duplicaci√≥n de c√≥digo
- [x] Lectura obligatoria de feature.md
- [x] Integraci√≥n completa Enhanced MCP Server

### üöß En Progreso
- [ ] Optimizaci√≥n de hit rate del cache (objetivo >85%)
- [ ] Refinamiento de algoritmos de relevancia
- [ ] Mejora de chunking sem√°ntico

### üìã Pendiente
- [ ] Machine Learning para predicci√≥n de consultas
- [ ] Dashboard de m√©tricas avanzadas
- [ ] Cache distribuido para m√∫ltiples instancias
- [ ] An√°lisis sem√°ntico con NLP

### üéØ Objetivos Inmediatos
1. **Validar hit rate >85%** en cache inteligente
2. **Probar sistema completo** con casos de uso reales
3. **Documentar flujos** de trabajo optimizados
4. **Implementar m√©tricas** de calidad de respuestas

### üìä M√©tricas Actuales
- **T√©cnicas implementadas**: 12/12 ‚úÖ
- **Compatibilidad**: 100% con servidor original ‚úÖ
- **Prevenci√≥n alucinaciones**: >80% reducci√≥n estimada ‚úÖ
- **Tiempo de respuesta**: <500ms objetivo ‚úÖ

---
**√öltima actualizaci√≥n**: {timestamp}
**Versi√≥n**: 2.0.0-enhanced
**Estado**: ‚úÖ PRODUCCI√ìN LISTA
"""
                
                with open(changelog_file, 'w', encoding='utf-8') as f:
                    import time
                    content = changelog_content.replace("{timestamp}", time.strftime('%Y-%m-%d %H:%M:%S'))
                    f.write(content)
                
                logger.info("üìã changelog.md creado autom√°ticamente")
            
            # Crear checklist.md si no existe
            checklist_file = self.priority_context_files["checklist"]
            if not checklist_file.exists():
                checklist_content = """# üìã Checklist del Proyecto - Modelo de Negocio, Reglas y Flujos

## üéØ Modelo de Negocio

### Prop√≥sito del Sistema
- **Servidor MCP Enhanced** para asistentes de IA (Windsurf/Cascade)
- **Prevenci√≥n de alucinaciones** mediante contexto inteligente
- **Cache multinivel** para m√°ximo rendimiento
- **Retroalimentaci√≥n continua** para mejora autom√°tica

### Valor Diferencial
- **12 t√©cnicas avanzadas** integradas en un solo sistema
- **Cache inteligente** con >85% hit rate
- **Feedback system** que aprende autom√°ticamente
- **Compatibilidad total** con optimizaciones existentes

## üìã Reglas de Negocio OBLIGATORIAS

### üî• Reglas Prioritarias (NUNCA VIOLAR)
1. **Leer feature.md SIEMPRE** antes de cualquier respuesta
2. **Analizar c√≥digo existente** antes de crear c√≥digo nuevo
3. **NO duplicar c√≥digo** - verificar existencia primero
4. **Ciclo de tareas**: 2 tareas ‚Üí contexto ‚Üí 1 tarea ‚Üí contexto
5. **Cache local primero** - si no hay match ‚Üí modelo ‚Üí guardar respuesta

### üõ°Ô∏è Reglas de Seguridad
- **No alucinaciones** - solo responder basado en contexto real
- **Citar fuentes** - referenciar archivos/l√≠neas espec√≠ficas
- **Validar respuestas** - verificar contra feature requirements
- **Trazabilidad completa** - log de todas las decisiones

### ‚ö° Reglas de Rendimiento
- **Hit rate >85%** en cache inteligente
- **Tiempo respuesta <500ms** para cache hits
- **L1 cache <100ms** acceso instant√°neo
- **Chunking sem√°ntico** preservando contexto

## üîÑ Flujos de Trabajo

### Flujo Principal: Consulta de Contexto
```
1. Usuario hace consulta
2. Leer feature.md (obligatorio)
3. Buscar en cache inteligente
   ‚îú‚îÄ HIT (>60% relevancia) ‚Üí Respuesta inmediata
   ‚îî‚îÄ MISS ‚Üí Continuar a paso 4
4. Consultar modelo optimizado
5. Guardar respuesta en cache (chunking)
6. Responder al usuario
7. Actualizar m√©tricas
```

### Flujo de An√°lisis de C√≥digo
```
1. Recibir solicitud de c√≥digo
2. Analizar c√≥digo existente (obligatorio)
3. Detectar duplicados
4. Verificar patrones arquitecturales
5. Solo entonces crear/modificar c√≥digo
6. Guardar an√°lisis en contexto
```

### Flujo de Gesti√≥n de Tareas
```
1. Crear tarea con an√°lisis previo
2. Procesar m√°ximo 2 tareas
3. Revisi√≥n de contexto (obligatoria)
4. Procesar 1 tarea adicional
5. Nueva revisi√≥n de contexto
6. Repetir ciclo
```

## üõ†Ô∏è Tecnolog√≠as y Stack

### Tecnolog√≠as Principales
- **Python 3.8+** - Lenguaje base
- **Pathlib** - Manejo de archivos
- **JSON** - Serializaci√≥n de datos
- **Threading** - Operaciones as√≠ncronas
- **Logging** - Sistema de logs

### Arquitectura del Sistema
- **Enhanced MCP Server** - Servidor principal
- **Intelligent Cache System** - Cache multinivel
- **Context Feedback System** - Prevenci√≥n alucinaciones
- **Optimized MCP Server** - Base con 7 optimizaciones

### Patrones de Dise√±o
- **Herencia** - Enhanced hereda de Optimized
- **Composici√≥n** - Cache + Feedback integrados
- **Strategy Pattern** - M√∫ltiples estrategias de cache
- **Observer Pattern** - Monitoreo de m√©tricas

## üìä M√©tricas y KPIs

### M√©tricas Cr√≠ticas
- **Hit Rate Cache**: >85% (obligatorio)
- **Tiempo Respuesta**: <500ms promedio
- **Prevenci√≥n Alucinaciones**: >80% reducci√≥n
- **Coherencia C√≥digo**: >95% consistencia

### M√©tricas de Calidad
- **Uptime**: >99.9%
- **Error Rate**: <1%
- **Memory Usage**: <100MB base
- **CPU Usage**: <10% promedio

### M√©tricas de Negocio
- **Consultas/d√≠a**: Tracking autom√°tico
- **Satisfacci√≥n**: Basada en feedback
- **Adopci√≥n**: Uso de herramientas avanzadas
- **Eficiencia**: Tiempo ahorrado vs manual

## üéØ Objetivos y Metas

### Objetivos Inmediatos (1 semana)
- [ ] Validar hit rate >85% en producci√≥n
- [ ] Completar suite de pruebas automatizadas
- [ ] Documentar casos de uso principales
- [ ] Optimizar algoritmos de relevancia

### Objetivos a Mediano Plazo (1 mes)
- [ ] Implementar machine learning para predicci√≥n
- [ ] Dashboard de m√©tricas en tiempo real
- [ ] Integraci√≥n con m√∫ltiples proyectos
- [ ] API REST para acceso externo

### Objetivos a Largo Plazo (3 meses)
- [ ] Cache distribuido multi-instancia
- [ ] An√°lisis sem√°ntico con NLP avanzado
- [ ] Integraci√≥n con bases de datos externas
- [ ] Sistema de recomendaciones inteligente

## üö® Criterios de √âxito

### ‚úÖ Sistema Exitoso Si:
1. **Hit rate >85%** mantenido consistentemente
2. **0 alucinaciones** detectadas en producci√≥n
3. **Tiempo respuesta <500ms** en 95% de consultas
4. **Compatibilidad 100%** con sistema original
5. **Feedback positivo** de usuarios finales

### ‚ùå Falla del Sistema Si:
1. Hit rate <70% por m√°s de 24 horas
2. Alucinaciones >5% de respuestas
3. Tiempo respuesta >2 segundos consistente
4. P√©rdida de funcionalidad del sistema base
5. Errores cr√≠ticos no resueltos en 1 hora

---
**Documento vivo** - Se actualiza autom√°ticamente
**Responsable**: Enhanced MCP System
**Revisi√≥n**: Autom√°tica con cada cambio significativo
"""
                
                with open(checklist_file, 'w', encoding='utf-8') as f:
                    f.write(checklist_content)
                
                logger.info("üìã checklist.md creado autom√°ticamente")
            
        except Exception as e:
            logger.error(f"Error creando archivos prioritarios: {e}")
    
    def _load_priority_context_immediately(self):
        """Carga inmediatamente los archivos prioritarios en cache"""
        
        if not CACHE_AVAILABLE or not self.intelligent_cache:
            return
        
        try:
            for context_type, file_path in self.priority_context_files.items():
                if file_path.exists():
                    # Forzar carga inmediata en L1 cache
                    self.intelligent_cache._cache_file_content(file_path)
                    logger.info(f"üî• {context_type}.md cargado en L1 cache (prioritario)")
                else:
                    logger.warning(f"‚ö†Ô∏è Archivo prioritario no encontrado: {file_path}")
            
            # Forzar actualizaci√≥n de √≠ndices
            self.intelligent_cache._save_cache_indexes()
            
        except Exception as e:
            logger.error(f"Error cargando contexto prioritario: {e}")
    
    def _save_response_to_cache_via_feedback(self, query: str, response: Dict):
        """Guarda la respuesta del modelo en cache mediante feedback system"""
        
        if not CACHE_AVAILABLE or not self.intelligent_cache:
            return
        
        try:
            # Extraer texto de la respuesta
            response_text = ""
            if "content" in response:
                for content_item in response["content"]:
                    if content_item.get("type") == "text":
                        response_text += content_item.get("text", "")
            
            if not response_text.strip():
                return
            
            # Crear archivo temporal con la respuesta para que el cache lo procese
            import tempfile
            import time
            
            timestamp = int(time.time())
            temp_filename = f"response_{timestamp}_{hash(query) % 10000}.md"
            
            # Formatear contenido para guardar
            content_to_save = f"""# Respuesta a: {query}

**Timestamp**: {time.strftime('%Y-%m-%d %H:%M:%S')}
**Query**: {query}

## Respuesta

{response_text}

---
*Generado autom√°ticamente por Enhanced MCP Server*
"""
            
            # Crear archivo temporal en el directorio de cache
            cache_responses_dir = self.intelligent_cache.cache_directory / "responses"
            cache_responses_dir.mkdir(exist_ok=True)
            
            temp_file_path = cache_responses_dir / temp_filename
            
            with open(temp_file_path, 'w', encoding='utf-8') as f:
                f.write(content_to_save)
            
            # Forzar que el cache procese este nuevo archivo
            self.intelligent_cache._cache_file_content(temp_file_path)
            
            logger.info(f"üíæ Respuesta guardada en cache: {temp_filename}")
            
        except Exception as e:
            logger.warning(f"Error guardando respuesta en cache: {e}")
    
    def _handle_context_query_cache_only(self, arguments: Dict) -> Dict[str, Any]:
        """Maneja consulta usando solo cache (modo compatibilidad)"""
        
        query = arguments.get("query", "")
        
        if not CACHE_AVAILABLE or not self.intelligent_cache:
            return {
                "content": [{
                    "type": "text", 
                    "text": "Cache no disponible y feedback system deshabilitado"
                }],
                "isError": True
            }
        
        try:
            cache_results = self.intelligent_cache.search(query, max_results=5)
            
            if cache_results:
                logger.info(f"‚úÖ Cache hit en modo compatibilidad: {len(cache_results)} resultados")
                return self._format_cache_response(cache_results, query)
            else:
                return {
                    "content": [{
                        "type": "text",
                        "text": f"üîç No se encontraron resultados en cache para: '{query}'\n\nSugerencia: El feedback system est√° deshabilitado. Habil√≠telo para obtener respuestas del modelo."
                    }]
                }
                
        except Exception as e:
            logger.error(f"Error en cache-only query: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error en b√∫squeda de cache: {str(e)}"
                }],
                "isError": True
            }
    
    def _handle_cache_search(self, arguments: Dict) -> Dict[str, Any]:
        """Maneja b√∫squeda directa en cache inteligente"""
        
        if not CACHE_AVAILABLE or not self.intelligent_cache:
            return {
                "content": [{
                    "type": "text",
                    "text": "Cache inteligente no disponible"
                }],
                "isError": True
            }
        
        query = arguments.get("query", "")
        max_results = arguments.get("max_results", 10)
        
        try:
            results = self.intelligent_cache.search(query, max_results)
            return self._format_cache_response(results, query)
            
        except Exception as e:
            logger.error(f"Error en b√∫squeda de cache: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error en b√∫squeda de cache: {str(e)}"
                }],
                "isError": True
            }
    
    def _handle_cache_metrics(self, arguments: Dict) -> Dict[str, Any]:
        """Maneja consulta de m√©tricas del cache"""
        
        if not CACHE_AVAILABLE or not self.intelligent_cache:
            return {
                "content": [{
                    "type": "text",
                    "text": "Cache inteligente no disponible"
                }],
                "isError": True
            }
        
        try:
            metrics = self.intelligent_cache.get_metrics()
            response_text = self._format_cache_metrics(metrics)
            
            return {
                "content": [{
                    "type": "text",
                    "text": response_text
                }]
            }
            
        except Exception as e:
            logger.error(f"Error obteniendo m√©tricas de cache: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error obteniendo m√©tricas: {str(e)}"
                }],
                "isError": True
            }
    
    def _handle_cache_refresh(self, arguments: Dict) -> Dict[str, Any]:
        """Maneja actualizaci√≥n forzada del cache"""
        
        if not CACHE_AVAILABLE or not self.intelligent_cache:
            return {
                "content": [{
                    "type": "text",
                    "text": "Cache inteligente no disponible"
                }],
                "isError": True
            }
        
        try:
            self.intelligent_cache.force_refresh()
            
            return {
                "content": [{
                    "type": "text",
                    "text": "‚úÖ Cache actualizado correctamente"
                }]
            }
            
        except Exception as e:
            logger.error(f"Error actualizando cache: {e}")
            return {
                "content": [{
                    "type": "text",
                    "text": f"Error actualizando cache: {str(e)}"
                }],
                "isError": True
            }
    
    def _format_cache_response(self, cache_results: List[Dict], query: str) -> Dict[str, Any]:
        """Formatea respuesta del cache inteligente"""
        
        if not cache_results:
            return {
                "content": [{
                    "type": "text",
                    "text": f"üîç No se encontraron resultados en cache para: '{query}'"
                }]
            }
        
        text = f"# üöÄ Resultados del Cache Inteligente\n\n"
        text += f"**Consulta**: {query}\n"
        text += f"**Resultados encontrados**: {len(cache_results)}\n\n"
        
        for i, result in enumerate(cache_results[:3], 1):
            relevance = result.get('relevance', 0)
            file_path = result.get('file_path', 'Desconocido')
            content = result.get('content', '')
            
            text += f"## üìÑ Resultado {i} (Relevancia: {relevance:.2%})\n"
            text += f"**Archivo**: `{Path(file_path).name}`\n"
            text += f"**Ruta**: `{file_path}`\n\n"
            
            # Mostrar fragmento relevante
            if len(content) > 500:
                text += f"```\n{content[:500]}...\n```\n\n"
            else:
                text += f"```\n{content}\n```\n\n"
        
        return {
            "content": [{
                "type": "text",
                "text": text
            }],
            "cache_metadata": {
                "results_count": len(cache_results),
                "max_relevance": max(r.get('relevance', 0) for r in cache_results),
                "cache_hit": True
            }
        }
    
    def _format_cache_metrics(self, metrics: Dict) -> str:
        """Formatea m√©tricas del cache"""
        
        text = "# üìä M√©tricas del Cache Inteligente\n\n"
        
        hit_rate = metrics.get('hit_rate', 0)
        l1_hit_rate = metrics.get('l1_hit_rate', 0)
        
        text += f"## üéØ Rendimiento General\n"
        text += f"**Hit Rate Total**: {hit_rate:.2%} {'‚úÖ' if hit_rate > 0.85 else '‚ö†Ô∏è'}\n"
        text += f"**L1 Hit Rate**: {l1_hit_rate:.2%}\n"
        text += f"**Total Requests**: {metrics.get('total_requests', 0)}\n\n"
        
        text += f"## üìà Distribuci√≥n de Hits\n"
        text += f"**L1 Cache Hits**: {metrics.get('l1_hits', 0)}\n"
        text += f"**L2 Cache Hits**: {metrics.get('l2_hits', 0)}\n"
        text += f"**Disk Cache Hits**: {metrics.get('disk_hits', 0)}\n"
        text += f"**Cache Misses**: {metrics.get('misses', 0)}\n\n"
        
        cache_sizes = metrics.get('cache_sizes', {})
        cache_limits = metrics.get('cache_limits', {})
        
        text += f"## üíæ Estado del Cache\n"
        text += f"**L1 Cache**: {cache_sizes.get('l1', 0)}/{cache_limits.get('l1', 0)} items\n"
        text += f"**L2 Cache**: {cache_sizes.get('l2', 0)}/{cache_limits.get('l2', 0)} items\n"
        text += f"**Disk Cache**: {cache_sizes.get('disk', 0)} items\n\n"
        
        text += f"## üìö Contenido Indexado\n"
        text += f"**Archivos indexados**: {metrics.get('total_indexed_files', 0)}\n"
        text += f"**Keywords indexadas**: {metrics.get('total_keywords', 0)}\n"
        
        return text
    
    def _combine_cache_and_original_response(self, cache_results: List[Dict], 
                                           original_response: Dict, query: str, 
                                           feature_requirements: Dict) -> Dict[str, Any]:
        """Combina resultados del cache con respuesta original"""
        
        # Extraer texto de respuesta original
        original_text = ""
        if "content" in original_response:
            for content_item in original_response["content"]:
                if content_item.get("type") == "text":
                    original_text += content_item.get("text", "")
        
        # Formatear respuesta combinada
        combined_text = f"# üîÑ Respuesta H√≠brida (Cache Local + Modelo + Feedback)\n\n"
        combined_text += f"**Flujo**: Cache Local üîç ‚Üí Modelo ü§ñ ‚Üí Feedback System üíæ\n\n"
        
        # Agregar resultados del cache si tienen buena relevancia
        if cache_results and cache_results[0].get('relevance', 0) > 0.5:
            combined_text += f"## üöÄ Desde Cache Inteligente\n\n"
            best_result = cache_results[0]
            combined_text += f"**Archivo**: `{Path(best_result['file_path']).name}`\n"
            combined_text += f"**Relevancia**: {best_result['relevance']:.2%}\n\n"
            
            content = best_result.get('content', '')
            if len(content) > 800:
                combined_text += f"```\n{content[:800]}...\n```\n\n"
            else:
                combined_text += f"```\n{content}\n```\n\n"
        
        # Agregar respuesta original si existe
        if original_text.strip():
            combined_text += f"## üìã Desde Contexto del Proyecto\n\n"
            combined_text += original_text
        
        # Verificar cumplimiento de feature requirements
        compliance_check = self._verify_response_compliance(combined_text, feature_requirements)
        
        return {
            "content": [{
                "type": "text",
                "text": combined_text
            }],
            "context_metadata": {
                "cache_results_count": len(cache_results),
                "original_response_included": bool(original_text.strip()),
                "compliance_check": compliance_check,
                "query_count": self.query_count,
                "feature_requirements_checked": True
            }
        }
    
    def handle_tools_list(self, params: Dict[str, Any]) -> Dict[str, Any]:
        """Lista herramientas disponibles incluyendo las nuevas"""
        
        # Obtener herramientas del servidor original
        original_tools = super().handle_tools_list(params)
        
        # Agregar nuevas herramientas
        enhanced_tools = original_tools.get("tools", [])
        
        enhanced_tools.extend([
            {
                "name": "analyze_code",
                "description": "Analiza c√≥digo existente para prevenir duplicaci√≥n",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "path": {
                            "type": "string",
                            "description": "Ruta del directorio a analizar (opcional)"
                        }
                    }
                }
            },
            {
                "name": "create_task",
                "description": "Crea una nueva tarea con an√°lisis de contexto",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "content": {
                            "type": "string",
                            "description": "Descripci√≥n de la tarea"
                        },
                        "priority": {
                            "type": "string",
                            "enum": ["low", "medium", "high", "critical"],
                            "description": "Prioridad de la tarea"
                        },
                        "dependencies": {
                            "type": "array",
                            "items": {"type": "string"},
                            "description": "IDs de tareas dependientes"
                        }
                    },
                    "required": ["content"]
                }
            },
            {
                "name": "process_tasks",
                "description": "Procesa tareas con retroalimentaci√≥n de contexto",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "cache_search",
                "description": "Busca directamente en el cache inteligente multinivel",
                "inputSchema": {
                    "type": "object",
                    "properties": {
                        "query": {
                            "type": "string",
                            "description": "Consulta para buscar en el cache"
                        },
                        "max_results": {
                            "type": "number",
                            "description": "N√∫mero m√°ximo de resultados",
                            "default": 10
                        }
                    },
                    "required": ["query"]
                }
            },
            {
                "name": "cache_metrics",
                "description": "Obtiene m√©tricas de rendimiento del cache inteligente",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            },
            {
                "name": "cache_refresh",
                "description": "Fuerza actualizaci√≥n completa del cache desde el directorio fuente",
                "inputSchema": {
                    "type": "object",
                    "properties": {}
                }
            }
        ])
        
        return {"tools": enhanced_tools}
    
    def run(self):
        """Ejecuta el servidor MCP mejorado"""
        logger.info("üöÄ Iniciando Enhanced MCP Server con Context Feedback System...")
        logger.info("Caracter√≠sticas activas:")
        logger.info("  ‚úÖ Prevenci√≥n de alucinaciones")
        logger.info("  ‚úÖ An√°lisis de c√≥digo existente obligatorio")
        logger.info("  ‚úÖ Lectura de feature.md antes de responder")
        logger.info("  ‚úÖ Gesti√≥n de tareas con retroalimentaci√≥n")
        logger.info("  ‚úÖ Detecci√≥n de duplicaci√≥n de c√≥digo")
        logger.info("  ‚úÖ Ciclo 2 tareas ‚Üí contexto ‚Üí 1 tarea ‚Üí contexto")
        
        if CACHE_AVAILABLE and self.intelligent_cache:
            logger.info("  üöÄ Cache Inteligente Multinivel:")
            logger.info("    üíæ L1: 100 items (acceso instant√°neo)")
            logger.info("    üíæ L2: 1000 items (datos frecuentes)")
            logger.info("    üíæ Disk: 10000+ items (hist√≥rico persistente)")
            logger.info("    üéØ Objetivo Hit Rate: >85%")
            logger.info("    üìÅ Alimentaci√≥n autom√°tica desde directorio")
            logger.info("    üîç B√∫squeda con chunking sem√°ntico")
        
        # Ejecutar el servidor base
        super().run()
    
    def shutdown(self):
        """Cierra el servidor limpiamente"""
        if CACHE_AVAILABLE and self.intelligent_cache:
            logger.info("Cerrando cache inteligente...")
            self.intelligent_cache.shutdown()
        
        logger.info("Enhanced MCP Server cerrado")

if __name__ == "__main__":
    server = EnhancedMCPServer()
    server.run()
