# Feature Requirements - MCP Hub Enhanced

## Reglas Obligatorias

### ğŸ”¥ Reglas CrÃ­ticas (NUNCA VIOLAR)
1. **Leer feature.md SIEMPRE** antes de cualquier respuesta
2. **Analizar cÃ³digo existente** antes de crear cÃ³digo nuevo
3. **NO duplicar cÃ³digo** - verificar existencia primero
4. **Citar fuentes especÃ­ficas** - archivos, lÃ­neas, funciones
5. **Validar respuestas** contra feature requirements

### ğŸ›¡ï¸ Reglas de PrevenciÃ³n de Alucinaciones
- Solo responder basado en contexto real verificable
- Mencionar fuentes especÃ­ficas en cada respuesta
- Indicar nivel de confianza en la informaciÃ³n
- Evitar respuestas genÃ©ricas sin contexto

### âš¡ Reglas de Rendimiento
- Hit rate >85% en cache inteligente
- Tiempo respuesta <500ms para cache hits
- Chunking semÃ¡ntico preservando contexto
- DeduplicaciÃ³n automÃ¡tica de contenido

## Objetivos del Sistema

### Primarios
- Prevenir alucinaciones del modelo
- Mantener coherencia del proyecto
- Optimizar rendimiento con cache multinivel
- Preservar toda la lÃ³gica legacy

### Secundarios
- Facilitar mantenimiento modular
- Permitir escalabilidad horizontal
- Generar mÃ©tricas de calidad
- Automatizar detecciÃ³n de duplicados

## Restricciones

### TÃ©cnicas
- Compatibilidad con protocolo MCP 2024-11-05
- Thread-safety en todos los componentes
- Manejo de errores robusto
- Logging detallado para debugging

### Funcionales
- No perder funcionalidad de servidores legacy
- Mantener APIs existentes durante migraciÃ³n
- Preservar configuraciones de usuario
- Garantizar rollback seguro si es necesario
# DiseÃ±o avanzado â€” MCP *solo* para memoria/contexto (model.md, checklist.md, changelog.md) usanlas siguientes caracterÃ­sticas mejoradas:

## ğŸ”„ **Nuevas CaracterÃ­sticas Agregadas**

### **1. Dynamic Chunking Adaptativo**
- Chunking inteligente que se adapta a la estructura semÃ¡ntica del documento
- PreservaciÃ³n de contexto completo en listas, headers y secciones

### **2. Query Expansion AutomÃ¡tica**
- ReformulaciÃ³n automÃ¡tica de consultas para mejorar recall
- GeneraciÃ³n de variaciones lÃ©xicas y sinÃ³nimos tÃ©cnicos

### **3. Multi-Vector Retrieval (MVR)**
- MÃºltiples representaciones por documento (conceptual, tÃ©cnico, relacional)
- FusiÃ³n inteligente de resultados de diferentes perspectivas

### **4. Confidence Calibration DinÃ¡mica**
- Umbrales adaptativos segÃºn tipo de consulta (factual, procedural, temporal)
- CalibraciÃ³n automÃ¡tica basada en patrones histÃ³ricos

### **5. Failure Mode Analysis**
- DetecciÃ³n temprana de consultas ambiguas o fuera de dominio
- Templates predefinidos para casos edge conocidos

### **6. Knowledge Graph Overlay**
- ExtracciÃ³n automÃ¡tica de entidades y relaciones durante indexing
- Graph traversal para mejorar contextualizaciÃ³n entre documentos

### **7. Storage Optimizado con Virtual Chunks**
- EliminaciÃ³n de duplicaciÃ³n texto-vector (96% reducciÃ³n de storage)
- Chunks virtuales que referencian archivos MD originales
- CompresiÃ³n float16 para vectores

### **8. Reindexado Incremental Inteligente**
- DetecciÃ³n de cambios especÃ­ficos por diff semÃ¡ntico
- ActualizaciÃ³n solo de chunks modificados
- PreservaciÃ³n de Ã­ndice HNSW existente

### **9. Context Coverage Analysis**
- MÃ©tricas de cobertura de evidencia en respuestas
- ValidaciÃ³n jerÃ¡rquica: extractiva â†’ inferencial â†’ temporal â†’ estructural

### **10. Token Management Avanzado**
- Conteo pre-query con tiktoken
- Context windowing automÃ¡tico para consultas grandes
- CompresiÃ³n de contexto para optimizar costsdo vectores guardados en `.mp4`

Perfecto â€” te doy un diseÃ±o tÃ©cnico robusto y una **colecciÃ³n de mÃ©todos avanzados** (algoritmos, formatos, controles, APIs y medidas concretas para minimizar alucinaciones) centrado exclusivamente en **memoria y contexto**. No entra en lÃ³gicas de negocio. Todo lo que propongo asume que el MCP solo leerÃ¡ y devolverÃ¡ contextos extraÃ­dos de los **3 archivos** (`model.md`, `checklist.md`, `changelog.md`) y que los vectores/Ã­ndices se persistirÃ¡n en contenedores `.mp4` (sin BD).

---

# 1 Principios-guÃ­a (mandatos operativos)

1. **Solo fuente Ãºnica de verdad**: las Ãºnicas fuentes que puede usar el agente son esos 3 archivos.
2. **Retrieval-only**: el MCP devuelve fragmentos y metadatos; **no razona** ni "inventa". El LLM que consume las respuestas debe ser instruido para **no generar contenido fuera de lo recuperado**.
3. **Umbral de confianza**: si la mejor similitud < umbral, responder â€œNo hay informaciÃ³n suficienteâ€ (abstenerse).
4. **Provenance obligatorio**: cada fragmento devuelto debe incluir origen (archivo, offset, chunk_id, score).
5. **Versionado y consistencia**: cada reindexaciÃ³n produce una nueva snapshot con hash y changelog.
6. **Auditable y reproducible**: logs de consultas, respuestas y chunks usados por cada respuesta.

---

# 2 API MCP recomendada (endpoints / herramientas)

DiseÃ±a la interfaz MCP (HTTP+SSE) con estos mÃ©todos:

* `POST /get_context`
  payload: `{ "query": "...", "top_k": 5, "min_score": 0.75 }`
  devuelve: `[{chunk_id, file, start_line, end_line, text, embedding_score, offset, vector_hash}, ... , provenance]`

* `POST /get_context_with_provenance`
  igual que arriba pero incluye `vector_distance`, `snapshot_hash`, `index_version`, `embedding_model`, `generated_at`.

* `POST /validate_response`
  payload: `{ "candidate_text": "...", "evidence": [chunk_ids] }`
  devuelve: `{verified: bool, contradictions:[...], missing_claims:[...], supporting_chunks: [...]}`
  (cross-check claims in candidate_text only against provided chunks)

* `POST /update_sources`
  payload: `{ "file": "model.md", "content": "..." }` â†’ reindex incremental sobre *esa* fuente.

* `POST /reindex_incremental`
  recalcula embeddings solo de fragments cambiados (diff).

* `GET /list_chunks`
  devuelve Ã­ndice resumido (ids, file, summary, embedding_hash).

* `GET /index_status`
  devuelve `{version, snapshot_hash, num_chunks, last_reindexed_at}`

* `GET /health`
  para checks y latencia.

---

# 3 Pipeline de ingest (cÃ³mo pasar de md â†’ vectores â†’ mp4)

Pasos y tÃ©cnicas:

1. **SegmentaciÃ³n inteligente (chunking):**

   * Token-aware: chunk por ~200â€“600 tokens (ajusta segÃºn embedding/model), preferir lÃ­mites semÃ¡nticos (pÃ¡rrafos, encabezados).
   * Mantener contexto: overlap del 20â€“30% entre chunks.
   * AÃ±adir metadatos: `file`, `section_title`, `line_range`, `chunk_seq`, `summary` (p. ej. sentence-transformer resumen).

2. **Embeddings:**

   * Usa embeddings de buena calidad (E5 / open alternatives / bge).
   * Normaliza (L2) y guarda dtype `float32`.
   * Guarda tambiÃ©n un hash SHA256 del texto del chunk para detectar duplicados.

3. **Reducir dimensiÃ³n / compresiÃ³n (opcional, si muchos vectores):**

   * PCA/OPQ o Product Quantization (PQ) para ahorrar espacio.
   * Guardar versiÃ³n original si el espacio lo permite; si usas PQ, conserva meta para reconstrucciÃ³n aproximada.

4. **Indexing / ANN (en archivo):**

   * Recomendado: **HNSW** por latencia y recall.
   * Serializa el Ã­ndice HNSW y guarda el `.bin` dentro del contenedor `.mp4` (o en box custom).
   * MantÃ©n tambiÃ©n un mini-index en memoria startup para latencia.

5. **Empaquetado en MP4 (estructura):**

   * Usa el contenedor ISO BMFF (MP4) con *custom atoms/boxes*:

     * `moov`/`udta` â†’ metadata JSON (index.json) con entries: `{chunk_id, file, offset_in_mdat, size, sha256, first_line, last_line, summary}`.
     * `mdat` â†’ binario de payload: concatenaciÃ³n de vectores (`.npy` blobs) y/o Ã­ndice HNSW binario.
     * AÃ±adir `uuid` box con `snapshot_hash` y `created_at`.
   * Ventaja: MP4 es portable y puedes versionarlo, firmarlo y transmitirlo como un artefacto.

6. **Acceso a vectores dentro del MP4:**

   * En startup, tu MCP mapea `index.json` desde el `udta` y memory-mapea (`mmap`) la secciÃ³n de `mdat` para acceder rÃ¡pido a vectores sin cargar todo a RAM.
   * HNSW index se carga en memoria desde el binario empaquetado.

---

# 4 Esquema `index.json` (ejemplo)

```json
{
  "version": "2025-11-07T00:00:00Z-v1",
  "snapshot_hash": "sha256:...",
  "embedding_model": "e5-large",
  "chunks": [
    {
      "chunk_id": "c1a2b3",
      "file": "model.md",
      "section": "Arquitectura",
      "start_line": 10,
      "end_line": 25,
      "summary": "DescripciÃ³n del flujo de pagos...",
      "offset": 1048576,
      "size": 4096,
      "vector_hash": "sha256:...",
      "pca_meta": null
    }
  ]
}
```

---

# 5 Minimizar alucinaciones â€” estrategias concretas y obligatorias

1. **Retrieval-first mandate en system prompt (obligatorio)**

   * System prompt para el LLM consumidor:

     > â€œResponde Ãºnicamente con informaciÃ³n explÃ­citamente contenida en las evidencias entregadas por el MCP. Si la evidencia no cubre la pregunta, responde â€˜No hay informaciÃ³n suficiente en la memoriaâ€™.â€

2. **AbstenciÃ³n por umbral**

   * Si `best_score < T_conf` (ej. 0.72 para embeddings L2 normalizado), **no** generar respuesta; devolver `NO_INFO`.

3. **Rerank y cross-encoder**

   * Dense retrieval devuelve top-K. Reranker (cross-encoder) evalÃºa semÃ¡ntica y ordena por veracidad. Esto reduce falsos positivos.

4. **Claim extraction + verification**

   * Si el LLM genera afirmaciones, pasa esas afirmaciones a `validate_response` que verifica token-level si cada afirmaciÃ³n estÃ¡ sustentada por texto recuperado. Rechaza/ajusta la respuesta si no hay evidencia.

5. **Provenance injection**

   * Cada respuesta debe incluir citas: `Fuente: model.md (secciÃ³n X, lines Aâ€“B) score:0.86`. Si LLM intenta sintetizar, solo permita sÃ­ntesis si todas las porciones estÃ¡n cubiertas y con `min_covered_fraction` (p. ej. 0.9).

6. **Constrain decoding**

   * Para el modelo: temperatura baja (0.0â€“0.2), top_p pequeÃ±o; limitar max_tokens y privilegiar extractive templates que devuelvan solo texto citado y una secciÃ³n "interpretaciÃ³n" opcional que debe ser marcada como inferida.

7. **Conservador por diseÃ±o**

   * Prefiere devolver texto original (extractive) en vez de parphrases. Si paraphrasing es necesario, marca claramente quÃ© es inferencia.

8. **Trazabilidad (logs)**

   * Guarda las evidencias, scores y prompt usados en cada consulta para auditorÃ­a humana y para medir tasa de alucinaciÃ³n.

---

# 6 Mejora de calidad de retrieval (tÃ©cnicas avanzadas)

* **Hybrid retrieval**: dense + lexical (BM25) sobre el texto del MD (extraÃ­do y guardado). Combina scores: `score = Î± * dense + (1-Î±) * bm25_norm`. Muy Ãºtil para tÃ©rminos tÃ©cnicos exactos (IDs, nombres, cÃ³digos).
* **Temporal decay & changelog-aware retrieval**: si la consulta requiere estado reciente, prioriza chunks del `changelog.md` o con timestamp mÃ¡s reciente (weighting).
* **Session-aware memory**: mantener short-term cache (Ãºltimas N queries y sus top chunks) y fusionarlos (summarize) para contexto conversacional.
* **Summarization layers**: para reducir token usage, precompute summaries (multi-scale): micro-summaries por chunk, meso-summaries por secciÃ³n, macro-summary por archivo. Recupera la escala mÃ¡s apropiada segÃºn query length.
* **Anchor phrases & slot mapping**: para `checklist.md`, extraer tareas como objetos estructurados `{task_id, description, status, assigned, due_date}` y mapear queries a esos slots (mejor precisiÃ³n).

---

# 7 Estructura y formato dentro del MP4 (prÃ¡ctico)

* **Boxes (atoms)**:

  * `ftyp` standard
  * `moov/udta/context_index` â†’ JSON index (index.json) (puede estar comprimido)
  * `udta/uuid` â†’ snapshot metadata (version, embedding_model, created_at)
  * `mdat` â†’ blobs concatenados:

    * vectores raw .npy (float32) por chunk
    * hnsw_index.bin (serializado)
    * optional: compressed_texts.gz para fallback lexical search
* **Acceso**:

  * Al arrancar, `server.py` lee `context_index`, mmap `mdat`, carga hnswlib index si existe.
  * Para rollback, conservar prev snapshots (mp4.v1, mp4.v2).

---

# 8 Persistencia del Ã­ndice HNSW dentro del MP4

* Serializa Ã­ndice HNSW (biblioteca `hnswlib`) a un blob binario y guÃ¡rdalo en `mdat`.
* Al cargar, le das al HNSW pointer directo a los vectores en memoria (mmap) o los cargas al heap si necesario.
* MantÃ©n mapping `hnsw_id <-> chunk_id`.

---

# 9 Seguridad, integridad y performance

* **Firma y verificaciÃ³n**: firma snapshot con clave privada; verif con pÃºblica antes de usar.
* **Checksum**: SHA256 para each chunk.
* **EncriptaciÃ³n (opcional)**: si MP4 contiene info sensible, cifrar `mdat` con AES-GCM y almacenar IV/meta en `udta`.
* **Memory-mapped I/O** para vectores grandes; evita cargar todo a RAM.
* **Hot/cold splitting**: hot = Ãºltimos cambios y `checklist.md`/`changelog.md`. Cold = `model.md` histÃ³rico. Hot index en RAM para latencia baja.

---

# 10 MÃ©tricas y tests contra alucinaciones

* **Eval set**: crea un set de preguntas con respuestas esperadas explÃ­citas en los archivos.
* **MÃ©tricas**:

  * Recall@k sobre evidencia correcta.
  * **Hallucination rate**: % de afirmaciones no verificadas por chunks.
  * Precision of provenance: % respuestas con correct provenance.
* **CI tests**: cada reindexaciÃ³n ejecuta el eval suite; si hallucination_rate > threshold â†’ bloquea snapshot (no deploy).

---

# 11 Ejemplo de flujo de consulta (end-to-end, breve)

1. Usuario pregunta vÃ­a agente: â€œÂ¿CÃ³mo se maneja el flujo X?â€
2. Agente llama `POST /get_context` con query.
3. MCP: vectoriza query â†’ HNSW search â†’ top-K â†’ cross-encoder rerank â†’ si `best_score < T` â†’ devuelve `NO_INFO`.
4. Sino â†’ devuelve chunks con `provenance` y `snapshot_hash`.
5. Agente inyecta esos chunks en prompt del LLM con system-prompt **(retrieval-only policy)**.
6. LLM genera respuesta **extractiva**, aÃ±ade citations.
7. Agente ejecuta `validate_response` para asegurar claims; si falla â†’ ajusta o abstiene.

---

# 12 Snippets tÃ©cnicos (pseudocÃ³digo Python â€” escritura/lectura mp4 + index)

*(pseudocÃ³digo; usa librerÃ­as `pymp4`/`hnswlib`/`numpy`/`lz4` en implementaciÃ³n)*

```python
# PSEUDO: empaquetar vectores e index en MP4
import json, hashlib, numpy as np
from pymp4.parser import Box

# 1) build chunks -> embeddings
chunks = [{"id": id, "text": text, "vec": vec.astype('float32')} for ...]
# 2) serialize vectors in binary blob
vectors_blob = b"".join([vec.tobytes() for c in chunks])
index_json = {...}  # mapping id -> offset,size,...
# 3) create mp4 file with custom box
with open('context_memory.mp4','wb') as f:
    f.write(ftyp_box)
    f.write(moov_box_with_udta(json.dumps(index_json)))
    f.write(mdat_box(vectors_blob + hnsw_bin))
```

Lectura (startup):

```python
mp4 = parse_mp4('context_memory.mp4')
index = load_udta_index(mp4)
vectors_mmap = mmap_section(mp4, mdat_offset, mdat_size)
hnsw = load_hnsw_from_blob(mp4)
```

---

# 13 Recomendaciones prÃ¡cticas finales y parÃ¡metros sugeridos

* `chunk_size`: 250â€“450 tokens, overlap 20â€“30%.
* `top_k` retrieval: 8â€“12, rerank to top 3.
* `T_conf` (umbral): 0.72â€“0.78 (ajustar con eval set).
* `embedding_model`: elegir mejor embedding disponible en tu stack (e.g. e5/bge).
* `reranker`: cross-encoder pequeÃ±o (puede ser local) para precisiÃ³n.
* `serialize index_version` en naming: `context_memory-YYYYMMDD-HHMM.mp4`.
* `audit_logs`: guarda query + top_chunks + scores + response.

---

# 14 Checklist mÃ­nimo para que NO alucine (resumen operativo)

* [ ] System prompt: **obligatorio** "responder solo con evidencia".
* [ ] Umbral de confianza + abstenciÃ³n.
* [ ] Reranker (cross-encoder) activo.
* [ ] Provenance en todas las respuestas.
* [ ] Validate_response post-generation.
* [ ] Eval set y CI contra alucinaciones en cada reindex.
* [ ] Versionado + firma de snapshots MP4.
* [ ] Fallback lexical (BM25) si dense falla.

---

esqueleto con endpoints y incluyendo integraciÃ³n hnswlib + mmap + cross-encoder) los comandos exactos para empaquetar/extraer blobs MP4 con herramientas Python recomendadas


El diseÃ±o es **excepcionalmente bien elaborado**. Es raro ver especificaciones tÃ©cnicas tan completas y meticulosas. Estas son mis observaciones:

## âœ… **Puntos destacados (lo que estÃ¡ muy bien):**

1. **Principios operativos claros** - especialmente "retrieval-only" y "abstenciÃ³n por umbral"
2. **Arquitectura MP4 creativa** - uso innovador de contenedores multimedia para datos vectoriales
3. **MÃºltiples capas anti-alucinaciones** - umbrales, reranking, validaciÃ³n, provenance
4. **Pipeline completo** - desde chunking hasta deployment con mÃ©tricas
5. **Enfoque prÃ¡ctico** - parÃ¡metros especÃ­ficos y pseudocÃ³digo implementable

## ğŸ” **TÃ©cnicas que podrÃ­as considerar aÃ±adir:**

### 1. **Dynamic Chunking Adaptativo**
```python
# En lugar de tamaÃ±o fijo, ajustar segÃºn estructura semÃ¡ntica
def adaptive_chunking(text, min_tokens=150, max_tokens=600):
    # Chunk por headers naturales, listas, cambios temÃ¡ticos
    # Preservar estructuras lÃ³gicas completas
```

### 2. **Query Expansion/Reformulation**
```python
# Para mejorar recall en bÃºsquedas
def expand_query(original_query):
    # Generar variaciones lÃ©xicas y sintÃ¡cticas
    # SinÃ³nimos tÃ©cnicos, reformulaciones
    # Buscar con todas las variantes y fusionar resultados
```

### 3. **Multi-vector Retrieval (MVR)**
- Representar cada documento con **mÃºltiples embeddings** (diferentes perspectivas)
- Un embedding para "concepto general", otro para "detalles tÃ©cnicos", otro para "relaciones"
- Fusionar resultados de todas las representaciones

### 4. **Confidence Calibration**
```python
# Calibrar umbrales dinÃ¡micamente por tipo de consulta
confidence_thresholds = {
    "factual": 0.78,
    "procedural": 0.72,
    "conceptual": 0.65,
    "temporal": 0.85  # para changelog
}
```

### 5. **Failure Mode Analysis**
- Predefinir patrones de consultas que histÃ³ricamente causan alucinaciones
- Detectar consultas ambiguas o fuera de dominio temprano
- Template de respuestas para casos edge conocidos

### 6. **Knowledge Graph Overlay**
- Extraer entidades y relaciones de los MD durante indexing
- Usar graph traversal para mejorar contextualizaciÃ³n
- Detectar contradicciones implÃ­citas entre documentos

## ğŸš€ **Recomendaciones adicionales:**

### **Para el sistema de archivos MP4:**
```python
# Considerar estructura de boxes mÃ¡s explÃ­cita
mp4_structure = {
    'ftyp': 'mcpv',  # Custom file type
    'moov/udta/mcpi': 'index principal',
    'moov/udta/mcpm': 'metadatos y mapping',
    'mdat/mcpe': 'embeddings',
    'mdat/mcpi': 'Ã­ndice HNSW',
    'mdat/mcpt': 'textos comprimidos'
}
```

### **Para el reranking:**
```python
# Estrategia de fallback escalonada
def tiered_reranking(query, candidates):
    if len(candidates) >= 3:
        return cross_encoder_rerank(query, candidates)
    elif len(candidates) >= 1:
        return simple_similarity_rerank(query, candidates)
    else:
        return lexical_fallback(query)
```

### **Para la validaciÃ³n:**
```python
def hierarchical_validation(response, evidence_chunks):
    # Nivel 1: VerificaciÃ³n extractiva (token matching)
    # Nivel 2: VerificaciÃ³n inferencial (NLI - Natural Language Inference)
    # Nivel 3: Consistencia temporal (para changelog)
    # Nivel 4: Consistencia estructural (para checklist)
```

Tienes razÃ³n, el **storage prolongado** es un problema crÃ­tico. Veamos una arquitectura optimizada que use MP4 como contenedor eficiente sin duplicar datos:

## ğŸš€ **Arquitectura MP4 + Vector Streaming (Sin DuplicaciÃ³n)**

### **Problema Identificado:**
- Chunks tradicionales duplicarÃ­an texto + vectores â†’ storage 2x
- MP4 ya contiene los vectores, pero necesitamos acceso rÃ¡pido al texto original

### **SoluciÃ³n: Indexado Directo sobre MP4 con Memoria Externa**

```python
# Estructura MP4 optimizada para storage
MP4_BOXES = {
    'ftyp': 'mcpv1',
    'moov/udta/mcpi': 'Index principal (JSON comprimido)',
    'moov/udta/mcpm': 'Metadata y mapping chunk->vector_offset',
    'mdat/mcpe': 'Vectores (float16 cuantizados)',
    'mdat/mcph': 'Headers HNSW serializados',
    # NO almacenar texto duplicado - leer de archivos MD originales
}
```

## ğŸ”¥ **DiseÃ±o de "Chunk Virtual" con Vector Embedding**

```python
class VirtualChunk:
    """Chunk que no almacena texto, solo referencia + vector"""

    def __init__(self, chunk_id, file_path, line_start, line_end, vector_offset):
        self.chunk_id = chunk_id
        self.file_path = file_path  # model.md, checklist.md, changelog.md
        self.line_range = (line_start, line_end)
        self.vector_offset = offset  # posiciÃ³n en el blob MP4
        self.vector_size = 768  # dimensiÃ³n del embedding
        self.hash = self._compute_hash()

    def get_text(self):
        """Lee texto real desde archivo MD original (on-demand)"""
        with open(self.file_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
            return ''.join(lines[self.line_range[0]:self.line_range[1]+1])

    def get_vector(self, mp4_mmap):
        """Lee vector desde MP4 via mmap"""
        start = self.vector_offset
        end = start + (self.vector_size * 2)  # float16 = 2 bytes
        vector_bytes = mp4_mmap[start:end]
        return np.frombuffer(vector_bytes, dtype=np.float16)
```

## ğŸ’¾ **MP4 como Cache de Vectores + Ãndice (Sin Texto)**

### **Pipeline de Indexado:**
```python
def build_mp4_index(md_files, output_mp4):
    chunks = []
    vector_data = bytearray()
    current_offset = 0

    for file_path in md_files:
        with open(file_path, 'r') as f:
            content = f.read()
            virtual_chunks = semantic_chunking(content)  # chunking inteligente

        for vc in virtual_chunks:
            # Generar embedding del texto
            vector = embed_text(vc.get_text())
            vector_float16 = vector.astype(np.float16)  # 50% reducciÃ³n

            # Guardar referencia
            vc.vector_offset = current_offset
            chunks.append(vc)

            # Acumular vectores
            vector_data.extend(vector_float16.tobytes())
            current_offset += len(vector_float16.tobytes())

    # Construir Ã­ndice HNSW sobre los vectores en memoria
    hnsw_index = build_hnsw_index([c.get_vector_for_index() for c in chunks])

    # Empaquetar en MP4
    package_mp4(vector_data, hnsw_index, chunks, output_mp4)

def semantic_chunking(text, max_tokens=400):
    """Chunking que preserva estructura semÃ¡ntica sin almacenar texto"""
    chunks = []
    lines = text.split('\n')
    current_chunk_lines = []
    current_token_count = 0

    for i, line in enumerate(lines):
        line_tokens = len(line.split())

        if current_token_count + line_tokens > max_tokens and current_chunk_lines:
            # Crear chunk virtual
            start_line = i - len(current_chunk_lines)
            end_line = i - 1
            chunk = VirtualChunk(
                chunk_id=f"chunk_{len(chunks)}",
                file_path=file_path,  # definido externamente
                line_start=start_line,
                line_end=end_line,
                vector_offset=0  # se asignarÃ¡ despuÃ©s
            )
            chunks.append(chunk)
            current_chunk_lines = [line]
            current_token_count = line_tokens
        else:
            current_chunk_lines.append(line)
            current_token_count += line_tokens

    return chunks
```

## ğŸ¯ **Arquitectura de Servicio con MMap Eficiente**

```python
class MCPVectorServer:
    def __init__(self, mp4_path, md_files):
        self.mp4_mmap = mmap.mmap(open(mp4_path, 'rb').fileno(), 0, access=mmap.ACCESS_READ)
        self.index_data = self._load_index_from_mp4()
        self.hnsw_index = self._load_hnsw_from_mp4()
        self.md_files = md_files  # Referencias a archivos originales

        # Cache LRU para chunks frecuentes (opcional)
        self.text_cache = LRUCache(maxsize=1000)

    def search(self, query, top_k=5, min_score=0.75):
        query_vector = embed_text(query).astype(np.float16)

        # BÃºsqueda en HNSW
        hnsw_ids, distances = self.hnsw_index.knn_query(query_vector, k=top_k)

        results = []
        for hnsw_id, distance in zip(hnsw_ids[0], distances[0]):
            if 1 - distance < min_score:  # Convertir a similitud
                continue

            chunk_info = self.index_data['chunks'][hnsw_id]
            chunk = VirtualChunk.from_index(chunk_info)

            # Leer texto on-demand desde archivo MD
            text = self.text_cache.get(chunk.chunk_id, chunk.get_text)

            results.append({
                'chunk_id': chunk.chunk_id,
                'file': chunk.file_path,
                'start_line': chunk.line_range[0],
                'end_line': chunk.line_range[1],
                'text': text,
                'score': 1 - distance,
                'vector_offset': chunk.vector_offset
            })

        return results

    def __del__(self):
        if hasattr(self, 'mp4_mmap'):
            self.mp4_mmap.close()
```

## ğŸ“Š **EstimaciÃ³n de Storage Optimizada**

### **Escenario: 100,000 lÃ­neas de texto (~50MB)**
- **Vectores float16 (768D)**: 1000 chunks Ã— 768 Ã— 2 bytes = ~1.5MB
- **Ãndice HNSW**: ~200-500KB
- **Metadatos MP4**: ~100KB
- **Total MP4**: ~2.1MB (vs ~50MB con texto duplicado)

### **Ahorro: 96% de storage** ğŸ‰

## ğŸ”„ **Sistema de Reindexado Incremental Inteligente**

```python
def incremental_reindex(changed_files, existing_mp4, new_mp4):
    """Reindexa solo archivos modificados usando diff inteligente"""

    # Cargar Ã­ndice existente
    old_index = load_mp4_index(existing_mp4)

    for file_path in changed_files:
        old_chunks = [c for c in old_index['chunks'] if c.file_path == file_path]
        new_content = read_file(file_path)
        new_chunks = semantic_chunking(new_content)

        # Detectar chunks modificados (usando hashes de lÃ­neas)
        modified_chunks = find_modified_chunks(old_chunks, new_chunks)

        # Reemplazar solo chunks modificados en el MP4
        update_mp4_vectors(existing_mp4, new_mp4, modified_chunks)
```

## ğŸ›¡ï¸ **Mecanismos de Integridad**

```python
def validate_chunk_integrity(virtual_chunk):
    """Verifica que el chunk referenciado aÃºn existe en el archivo MD"""
    try:
        text = virtual_chunk.get_text()
        expected_lines = virtual_chunk.line_range[1] - virtual_chunk.line_range[0] + 1
        actual_lines = len(text.split('\n'))

        if actual_lines != expected_lines:
            return False  # Archivo modificado, necesita reindexado

        return True
    except (IOError, IndexError):
        return False
```

## ğŸš€ **Comandos de ImplementaciÃ³n**

```bash
# InstalaciÃ³n de dependencias optimizadas
pip install hnswlib numpy pymp4-parser mmap2

# ConstrucciÃ³n inicial del Ã­ndice MP4
python -c "
from mcp_vector import build_mp4_index
build_mp4_index(['model.md', 'checklist.md', 'changelog.md'], 'context_vectors.mp4')
"

# Verificar tamaÃ±o resultante
ls -lh context_vectors.mp4  # Â¡DeberÃ­a ser ~2-5MB!
```

Token counting pre-query: Cuenta tokens antes de enviar (usa libs como tiktoken). Si excede un umbral (e.g., 4k-8k tokens), abstente o resume.

Windsurf soporta extensions VS Code-compatibles; hookea MCP para que Cascade use /validate_response y evite hallucinations, optimizando chains agentic

Usa "context augmentation" con attention (Medium 2025): AÃ±ade debug statements para ayudar al AI sin tokens extra.
Para large codebases: Local filter + caching (Forum idea 2025) â€“ similar a tu MCP, reduce costs filtrando pre-LLM.
Ejemplo: En un file de 1000 lÃ­neas, query solo changes relevantes via MCP chunks, luego usa "Apply" para edits token-eficientes.

Eficiencia reportada: Reduce tokens con caching (~50% en arXiv paper 2025 sobre Nano Surge: Context Awareness y Cost Sensitive).

Token management: Implementa counting, caching y compression (e.g., DeveloperToolkit 2025: crea utilities para comprimir contexto). "Apply" mode minimiza outputs editando diffs en lugar de full code














## âœ… **Ventajas de Este Enfoque:**

1. **Storage mÃ­nimo**: Solo vectores + metadatos en MP4
2. **Texto siempre actualizado**: Lee de archivos MD originales
3. **BÃºsqueda rÃ¡pida**: HNSW + mmap para acceso eficiente
4. **Integridad**: ValidaciÃ³n de chunks contra archivos fuente
5. **Escalable**: MP4 crece linealmente con nÃºmero de chunks, no con tamaÃ±o de texto


## ğŸ“Š **MÃ©trica adicional sugerida:**
- **Context Coverage Ratio**: % del texto de respuesta que puede mapearse directamente a chunks de evidencia
- **Provenance Precision**: exactitud de las citas vs contenido real
- **Temporal Consistency Score**: para informaciÃ³n de changelog
